{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import Utilities as ut\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Neural network libraries\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Open the dataset\n",
    "df = pd.read_csv(\"dataset/Other/dataset.csv\", index_col = [0])\n",
    "#Drop useless columns\n",
    "df = df.drop([\"MW\", \"home_team_name\", \"away_team_name\"],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling only certains rows (excluding dummies)\n",
    "df[ut.scale_col] = scaler.fit_transform(df[ut.scale_col])\n",
    "\n",
    "# Dropping our goal\n",
    "X = df.drop('Result', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Result\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Normalize the y\n",
    "le.fit([\"A\",\"D\",\"H\"])\n",
    "y = le.transform(y)\n",
    "\n",
    "# Reshape the array \n",
    "transformed_y = y.reshape(-1, 1)\n",
    "\n",
    "# Trasform the 3 classes in matrix\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(transformed_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split of the scaled dataset in train and test\n",
    "\n",
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'val_loss', patience = 7)\n",
    "\n",
    "# Set the optimizer\n",
    "adam = optimizers.Adam(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network\n",
    "We build a Neural Network in order to predict football match results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/440px-Artificial_neural_network.svg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14353b550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Create the input layer \n",
    "model.add(Dense(y.shape[1]*16, input_shape = (X.shape[1],),\n",
    "                activation = 'relu'))\n",
    "# Dropping neurons\n",
    "model.add(Dropout(0.5, seed = 23))\n",
    "\n",
    "# Create a hidden layer\n",
    "model.add(Dense(y.shape[1]*8, activation = 'relu'))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(y.shape[1], activation = 'softmax')) # Away, Draw or Home\n",
    "          \n",
    "# Compile the module\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train and fit the model\n",
    "model.fit(X_train, y_train, batch_size = 100, validation_split = 0.01, epochs = 250,\n",
    "         verbose = 0, callbacks = [esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 0s 92us/step\n",
      "0.5696969628334045\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the keras model\n",
    "accuracy =  model.evaluate(X_test, y_test)\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 48)                4704      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 5,955\n",
      "Trainable params: 5,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is room for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Neural Networks</b> perform better with a larger dataset and with some particular circumstances. The model tends to overfit and tuning hyperparameters could help to avoid this risk. Furthermore, it looks like the dropout doesn't work or even makes the situation worse: a dataframe with more rows would help to prevent this and would perform better with the dropout."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
